'use strict';
const proximity = require('../util/proximity.js');
const queue = require('d3-queue').queue;
const coalesce = require('@mapbox/carmen-cache').coalesce;
const bbox = require('../util/bbox.js');
const termops = require('../text-processing/termops');
const constants = require('../constants');

module.exports = spatialmatch;
module.exports.stackable = stackable;
module.exports.rebalance = rebalance;
module.exports.allowed = allowed;
module.exports.sortByRelevLengthIdx = sortByRelevLengthIdx;
module.exports.sortByZoomIdx = sortByZoomIdx;

/**
* spatialmatch determines whether indexes can be spatially stacked and discards indexes that cannot be stacked together
*
* @access public
*
* @param {Array} query a list of terms composing the query to Carmen
* @param {Array} phrasematchResults for subquery permutations generated by ./lib/phrasematch
* @param {Object} options passed in with the query
* @param {function} callback callback called with indexes that could be spatially stacked
**/

function spatialmatch(query, phrasematchResults, options, callback) {
    let stacks;

    if (phrasematchResults.length) {
        // Fuzzy matching may have produced multiple phrasematches that will
        // behave identically when stacking -- they come from the same index
        // and have the same mask and weight. To avoid duplicate effort, we
        // collapse our matches down to ones that are distinct along these axes,
        // then expand them back out again after stacking.
        const archetypes = collapseToArchetypes(phrasematchResults);
        let arch_stacks = stackable(archetypes, options.stackable_limit);
        arch_stacks = allowed(arch_stacks, options);
        arch_stacks.forEach((arch_stack) => { arch_stack.sort(sortByZoomIdx); });
        arch_stacks.sort(sortByRelevLengthIdx);
        arch_stacks = arch_stacks.slice(0, options.spatialmatch_stack_limit);
        stacks = expandFromArchetypes(arch_stacks, options.spatialmatch_stack_limit);
    } else {
        stacks = [];
    }

    // Rebalance weights, relevs of stacks here.
    for (let i = 0; i < stacks.length; i++) {
        stacks[i] = rebalance(query, stacks[i]);
    }

    const waste = [];

    coalesceStacks();

    // coalesce all stacks.
    function coalesceStacks() {
        const q = queue();
        for (let i = 0; i < stacks.length; i++) q.defer(coalesceStack, stacks[i]);
        q.awaitAll(coalesceFinalize);
    }

    // Coalesce a single stack, add debugging info.
    function coalesceStack(stack, callback) {
        // Proximity option is set.
        // Convert proximity to xy @ highest zoom level for this stack
        const coalesceOpts = {};
        if (options) {
            if (options.proximity) {
                let l = stack.length;
                let maxZoom = 0;
                while (l--) maxZoom = Math.max(maxZoom, stack[l].zoom);
                coalesceOpts.centerzxy = proximity.center2zxy(
                    options.proximity,
                    maxZoom
                );
                coalesceOpts.radius = constants.COALESCE_PROXIMITY_RADIUS;
            }

            if (options.bbox) {
                coalesceOpts.bboxzxy = bbox.insideTile(options.bbox, stack[0].zoom);
            }
        }

        coalesce(stack, coalesceOpts, (err, cacheSpatialmatches) => {
            // Include text for debugging with each matched feature.
            const byIdx = stackByIdx(stack);
            cacheSpatialmatches = cacheSpatialmatches || [];

            if (cacheSpatialmatches.length === 0) {
                waste.push(Object.keys(byIdx));
            }

            const spatialmatches = [];
            for (let i = 0; i < cacheSpatialmatches.length; i++) {
                spatialmatches.push(new Spatialmatch(cacheSpatialmatches[i], byIdx));
            }

            callback(null, spatialmatches);
        });
    }

    // Final feature collection and sort.
    function coalesceFinalize(err, results) {
        if (err) return callback(err);
        let combined = [];
        combined = combined.concat.apply(combined, results);
        combined.sort(sortByRelev);

        // Ascending and Descending order here refers to being able to support `address, place, region, country` and `country, region, place, address`
        // Also supports being able to return a single feature that hasn't been stacked with another index
        const sets = {};
        const doneAscending = {};
        const doneDescending = {};
        const doneSingle = {};
        const filteredSpatialmatches = [];
        for (let i = 0; i < combined.length; i++) {
            const spatialmatch = combined[i];
            const covers = spatialmatch.covers;
            for (let j = 0; j < covers.length; j++) {
                if (!sets[covers[j].tmpid] || sets[covers[j].tmpid].relev < covers[j].relev) sets[covers[j].tmpid] = covers[j];
            }
            // only allow one result in each direction
            if (covers.length > 1 && covers[0].idx > covers[1].idx && !doneDescending[covers[0].tmpid]) {
                doneDescending[covers[0].tmpid] = true;
                filteredSpatialmatches.push(spatialmatch);
            } else if (covers.length > 1 && covers[0].idx < covers[1].idx && !doneAscending[covers[0].tmpid]) {
                doneAscending[covers[0].tmpid] = true;
                filteredSpatialmatches.push(spatialmatch);
            } else if (covers.length === 1 && !doneAscending[covers[0].tmpid] && !doneDescending[covers[0].tmpid] && !doneSingle[covers[0].tmpid]) {
                doneSingle[covers[0].tmpid] = true;
                filteredSpatialmatches.push(spatialmatch);
            }
        }

        return callback(null, { results: filteredSpatialmatches, sets: sets, waste: waste });
    }
}

function collapseToArchetypes(phrasematchResults) {
    const outResults = [];
    for (const inResult of phrasematchResults) {
        const uniqMap = new Map();
        for (const inMatch of inResult.phrasematches) {
            const signature = inMatch.mask + '-' + inMatch.weight + '-' + inMatch.editMultiplier;
            let outMatch = uniqMap.get(signature);
            if (!outMatch) {
                outMatch = {
                    mask: inMatch.mask,
                    weight: inMatch.weight,
                    editMultiplier: inMatch.editMultiplier,
                    zoom: inMatch.zoom,
                    idx: inResult.idx,
                    scorefactor: inMatch.scorefactor,
                    proxMatch: inMatch.proxMatch,
                    exemplars: []
                };
                uniqMap.set(signature, outMatch);
            }
            outMatch.exemplars.push(inMatch);
        }
        outResults.push({
            phrasematches: Array.from(uniqMap.values()),
            idx: inResult.idx,
            nmask: inResult.nmask,
            bmask: inResult.bmask
        });
    }
    return outResults;
}

function expandFromArchetypes(stacks, maxOut) {
    const out = [];
    for (const stack of stacks) {
        const done = expandFromArchetypesInner(stack, maxOut, 0, [], out);
        if (done) break;
    }
    return out;
}

function expandFromArchetypesInner(stack, maxOut, matchIdx, soFar, out) {
    if (matchIdx === stack.length - 1) {
        // this is innermost recursion round
        for (const exemplar of stack[matchIdx].exemplars) {
            const outStack = soFar.slice();
            outStack.push(exemplar);
            outStack.relev = stack.relev;
            outStack.adjRelev = stack.adjRelev;
            out.push(outStack);
            if (out.length >= maxOut) return true;
        }
        return false;
    } else {
        for (const exemplar of stack[matchIdx].exemplars) {
            const outStack = soFar.slice();
            outStack.push(exemplar);
            const done = expandFromArchetypesInner(stack, maxOut, matchIdx + 1, outStack, out);
            if (done) return done;
        }
        return false;
    }
}

// Filter an array of stacks down to only those whose maxidx is allowed
// by a passed in allowed_idx filter.
function allowed(stacks, options) {
    if (!options.allowed_idx) return stacks;
    const filtered = [];
    for (let i = 0; i < stacks.length; i++) {
        let stack_maxidx = 0;
        for (let j = 0; j < stacks[i].length; j++) {
            stack_maxidx = Math.max(stack_maxidx, stacks[i][j].idx);
        }
        if (options.allowed_idx[stack_maxidx]) {
            filtered.push(stacks[i]);
        }
    }
    return filtered;
}

function stackByIdx(stack) {
    const byIdx = {};
    let l = stack.length;
    while (l--) byIdx[stack[l].idx] = stack[l];
    return byIdx;
}

// For a given set of phrasematch results across multiple indexes,
// provide all relevant stacking combinations using phrase masks to
// exclude colliding matches.
// Features can't be stacked together if:
// 1. The bmask of an index represents a mask of all indexes that their geocoder_stacks do not intersect with, so if an index's bmask contains
// the idx of the next index they cannot be stacked together
// 2. The nmask of an index is the bitmasks of all the tokens in the subquery. Two indexes that have the same nmask should not be stacked together. For example: `main st` in new york and `st martin` in new york shouldn't be stacked together
// 3. If two features have the same mask values they shouldn't be stacked together

/**
*
* stackable
* @params {Array} phrasematchResults generated for each subquery permutation
* @params {Object} memo memoization object, used for caching result to check relevance, masks across different indexes
* @params {Number} idx index number
* @params {Number} mask caluculated by phrasematch; is used to represent all possible cominations
* @params {Number} nmask used to determine whether to two indexes have the same tokens which means they cannot be stacked together
* @params {Array} stack a list of indexes that stack spatially
* @params {Number} relevance score for each feature
**/
function stackable(phrasematchResults, limit) {
    const memo = {
        stacks: new Map(),
        minRelev: 100,
        count: 0
    };
    const idx = 0;
    const mask = 0;
    const stack = [];
    const relev = 0;
    const adjRelev = 0;

    const bins = {};
    for (const resultSet of phrasematchResults) {
        bins[resultSet.nmask] = bins[resultSet.nmask] || [];
        bins[resultSet.nmask].push(resultSet);
    }

    const binKeys = Object.keys(bins).sort((a, b) => a - b);

    const binnedResults = [];
    for (const key of binKeys) {
        binnedResults.push({ nmask: key, results: bins[key] });
    }
    return binnedStackable(binnedResults, limit, memo, idx, mask, stack, relev, adjRelev);
}

function binnedStackable(binnedResults, limit, memo, idx, mask, stack, relev, adjRelev) {
    // Recurse, skipping this level
    if (binnedResults[idx + 1] !== undefined) {
        binnedStackable(binnedResults, limit, memo, idx + 1, mask, stack, relev, adjRelev);
    }

    outerLoop:
    for (const phrasematchResult of binnedResults[idx].results) {
        // For each stacked item check the next bmask for its idx.
        // If the bmask includes the idx these indexes cannot stack
        // (their geocoder_stack do not intersect at all).
        const bmask = phrasematchResult.bmask;
        for (let j = 0; j < stack.length; j++) {
            if (bmask[stack[j].idx]) continue outerLoop;
        }

        // Recurse, including this level
        const phrasematches = phrasematchResult.phrasematches;
        for (let i = 0; i < phrasematches.length; i++) {
            const next = phrasematches[i];
            if (mask & next.mask) continue;

            // compare index order to input order to determine direction
            if (stack.length &&
                stack[0].idx >= next.idx &&
                mask &&
                mask < next.mask) continue;

            const targetStack = stack.slice(0);
            const targetMask = mask | next.mask;
            targetStack.relev = relev + next.weight;
            targetStack.adjRelev = adjRelev + (next.weight * next.editMultiplier);

            // ensure order of targetStack maintains lowest mask value at the
            // first position. ensure direction check above works.
            if (next.mask < mask) {
                targetStack.unshift(next);
            } else {
                targetStack.push(next);
            }

            if (targetStack.relev > 0.5) {
                // if we're below the limit, we can keep this one no matter what
                if (memo.count < limit) {
                    // find the bucket or make it
                    let bucket = memo.stacks.get(targetStack.relev);
                    if (!bucket) {
                        bucket = [];
                        memo.stacks.set(targetStack.relev, bucket);
                    }
                    bucket.push(targetStack);
                    if (targetStack.relev < memo.minRelev) memo.minRelev = targetStack.relev;
                    memo.count++;

                // if we're at our limit, it's one in one out, so we only add
                // one if there's a worse one on the bottom to remove
                } else if (targetStack.relev > memo.minRelev) {
                    // first add the new one, creating a bucket if necessary
                    let bucket = memo.stacks.get(targetStack.relev);
                    if (!bucket) {
                        bucket = [];
                        memo.stacks.set(targetStack.relev, bucket);
                    }
                    bucket.push(targetStack);
                    // remove from the bottom bucket
                    const minBucket = memo.stacks.get(memo.minRelev);
                    minBucket.length--;
                    if (minBucket.length === 0) {
                        // the bottom one is empty, so nuke it and set
                        // the min to the next smallest
                        memo.stacks.delete(memo.minRelev);
                        memo.minRelev = Math.min(...memo.stacks.keys());
                    } else if (minBucket.length >= limit) {
                        // we were in a state where we weren't constraining the size and now we have to
                        minBucket.length = limit - 1;
                    }
                } else if (targetStack.relev === memo.minRelev && memo.stacks.size === 1) {
                    // we only have items at the max relev now, so we're not going to constrain the size of this bucket
                    memo.stacks.get(targetStack.relev).push(targetStack);
                }
            }

            // Recurse to next level
            if (binnedResults[idx + 1] !== undefined) {
                binnedStackable(binnedResults, limit, memo, idx + 1, targetMask, targetStack, targetStack.relev, targetStack.adjRelev);
            }
        }
    }

    if (idx === 0) {
        const stacks = Array.prototype.concat(...memo.stacks.values());
        for (const stack of stacks) {
            // this will hyperbolically scale from 1 asymptotically down to .9
            const lengthPenalty = .9 + (.1 / (stack.length || 1));
            stack.adjRelev *= lengthPenalty;
        }
        return stacks;
    }
}

/**
* sortByRelevLengthIdx Sorts the stacks according to the scorefactor, relevance or length
**/
function sortByRelevLengthIdx(a, b) {
    const first = (b.adjRelev - a.adjRelev) ||
        (a.length - b.length) ||
        (b.relev - a.relev) ||
        (b[b.length - 1].proxMatch - a[a.length - 1].proxMatch) ||
        (b[b.length - 1].scorefactor - a[a.length - 1].scorefactor);
    if (first) return first;

    for (let end = a.length - 1; end >= 0; end--) {
        const second = a[end].idx - b[end].idx;
        if (second) return second;
    }
}

/**
* sortByZoomIdx Sorts stacks by zoom level
**/
function sortByZoomIdx(a, b) {
    return (a.zoom - b.zoom) || (a.idx - b.idx) || (b.mask - a.mask);
}

/**
* sortByRelev Sorts stack by relevance
**/
function sortByRelev(a, b) {
    return (b.relev - a.relev) ||
        (b.covers[0].scoredist - a.covers[0].scoredist) ||
        (a.covers[0].idx - b.covers[0].idx);
}


// Rebalancing is done to prevent cases where the number of tokens causes the relevance to cause an index to win
// over an index that actually has the feature
// For example: Martin Luther King Jr. Street, Thanjavur, Tamil Nadu would return an American city
// since Martin Luther King Jr. Street is a really long street name
// any result that contains the street(like Martin Luther King Jr. Street, Washington, DC would automatically have a higher relevance.
/**
* rebalance recalculates the relevance based on the number of tokens and number of layers that match in the result and query
* @param {Array} query a list of terms composing the query to Carmen
* @param {Array} stack results for a subquery combination
**/
function rebalance(query, stack) {
    let stackMask = 0;
    const stackClone = [];

    for (let i = 0; i < stack.length; i++) {
        stackMask |= stack[i].mask;
    }

    const garbage = (query.length === (stackMask.toString(2).split(1).length - 1)) ? 0 : 1;
    const weightPerMatch = 1 / (garbage + stack.length);

    // shallow copy stack into stackClone to prevent cases where a stack's
    // index gets overwritten in deep copies.
    let totalWeight = 0;
    for (let k = 0; k < stack.length; k++) {
        stackClone[k] = stack[k].clone();
        stackClone[k].weight = weightPerMatch * stack[k].editMultiplier;
        totalWeight += stackClone[k].weight;
    }

    stackClone.relev = totalWeight;

    return stackClone;
}

/**
Spatialmatch recursive function to fetch the features for stacks that could be spatially stacked together
**/

function Spatialmatch(cacheSpatialmatch, stackByIdx) {
    this.relev = cacheSpatialmatch.relev;
    this.covers = [];
    for (let i = 0; i < cacheSpatialmatch.length; i++) {
        const cacheCover = cacheSpatialmatch[i];
        this.covers.push(new Cover(cacheCover, stackByIdx[cacheCover.idx]));
    }
}

function Cover(cacheCover, phrasematch) {
    this.x = cacheCover.x;
    this.y = cacheCover.y;
    this.relev = cacheCover.relev;
    this.id = cacheCover.id;
    this.idx = cacheCover.idx;
    this.tmpid = cacheCover.tmpid;
    this.distance = cacheCover.distance;
    this.score = termops.decode3BitLogScale(cacheCover.score, phrasematch.scorefactor);
    this.scoredist = cacheCover.scoredist > 7 ? (phrasematch.scorefactor / 7) * cacheCover.scoredist : termops.decode3BitLogScale(cacheCover.scoredist, phrasematch.scorefactor);
    this.scorefactor = phrasematch.scorefactor;
    this.matches_language = cacheCover.matches_language;
    this.prefix = phrasematch.prefix;

    this.mask = phrasematch.mask;
    this.text = phrasematch.subquery.join(' ');
    this.zoom = phrasematch.zoom;
}
