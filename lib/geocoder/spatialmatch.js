'use strict';
const fs = require('fs');
const proximity = require('../util/proximity.js');
const queue = require('d3-queue').queue;
const coalesce = require('@mapbox/carmen-cache').coalesce;
const bbox = require('../util/bbox.js');
const termops = require('../text-processing/termops');
const constants = require('../constants');

const constant_values = `${constants.SPATIALMATCH_STACK_LIMIT},${constants.STACKABLE_LIMIT},${constants.VERIFYMATCH_STACK_LIMIT}`;
const NS_PER_SEC = 1e9;
const time = process.hrtime();
let spatialmatchStart;
let diff;

module.exports = spatialmatch;
module.exports.stackable = stackable;
module.exports.rebalance = rebalance;
module.exports.allowed = allowed;
module.exports.sortByRelevLengthIdx = sortByRelevLengthIdx;
module.exports.sortByZoomIdx = sortByZoomIdx;

function hrtime_format(hrt) {
    return `${hrt[0] * NS_PER_SEC + hrt[1]}`;
}
const prof_file = fs.createWriteStream('/tmp/spatialmatch-profile.log', {flags : 'a'});

/**
* spatialmatch determines whether indexes can be spatially stacked and discards indexes that cannot be stacked together
*
* @access public
*
* @param {Array} query a list of terms composing the query to Carmen
* @param {Array} phrasematchResults for subquery permutations generated by ./lib/phrasematch
* @param {Object} options passed in with the query
* @param {function} callback callback called with indexes that could be spatially stacked
**/

function spatialmatch(query, phrasematchResults, options, callback) {
    spatialmatchStart = process.hrtime();
    let stacks;
    prof_file.write(
        `SPATIALMATCH_STACK_LIMIT,STACKABLE_LIMIT,VERIFYMATCH_STACK_LIMIT,phase,time_offset\n`
    );

    if (phrasematchResults.length) {
        // Fuzzy matching may have produced multiple phrasematches that will
        // behave identically when stacking -- they come from the same index
        // and have the same mask and weight. To avoid duplicate effort, we
        // collapse our matches down to ones that are distinct along these axes,
        // then expand them back out again after stacking.
        const archetypes = collapseToArchetypes(phrasematchResults);
        let arch_stacks = stackable(archetypes, options.stackable_limit);
        arch_stacks = allowed(arch_stacks, options);
        arch_stacks.forEach((arch_stack) => { arch_stack.sort(sortByZoomIdx); });
        diff = hrtime_format(process.hrtime(spatialmatchStart));
        prof_file.write(`${constant_values},sortByZoomIdx,${diff}\n`);
        arch_stacks.sort(sortByRelevLengthIdx);
        diff = hrtime_format(process.hrtime(spatialmatchStart));
        prof_file.write(`${constant_values},sortByRelevLengthIdx,${diff}\n`);
        arch_stacks = arch_stacks.slice(0, options.spatialmatch_stack_limit);
        stacks = expandFromArchetypes(arch_stacks, options.spatialmatch_stack_limit);
    } else {
        stacks = [];
    }

    // Rebalance weights, relevs of stacks here.
    for (let i = 0; i < stacks.length; i++) {
        stacks[i] = rebalance(query, stacks[i]);
    }

    const waste = [];

    coalesceStacks();

    // coalesce all stacks.
    function coalesceStacks() {
        const q = queue();
        for (let i = 0; i < stacks.length; i++) q.defer(coalesceStack, stacks[i]);
        q.awaitAll(coalesceFinalize);
    }

    // Coalesce a single stack, add debugging info.
    function coalesceStack(stack, callback) {
        // Proximity option is set.
        // Convert proximity to xy @ highest zoom level for this stack
        const coalesceOpts = {};
        if (options) {
            if (options.proximity) {
                let l = stack.length;
                let maxZoom = 0;
                while (l--) maxZoom = Math.max(maxZoom, stack[l].zoom);
                coalesceOpts.centerzxy = proximity.center2zxy(
                    options.proximity,
                    maxZoom
                );
                coalesceOpts.radius = constants.PROXIMITY_RADIUS;
            }

            if (options.bbox) {
                coalesceOpts.bboxzxy = bbox.insideTile(options.bbox, stack[0].zoom);
            }
        }

        coalesce(stack, coalesceOpts, (err, cacheSpatialmatches) => {
            // Include text for debugging with each matched feature.
            const byIdx = stackByIdx(stack);
            cacheSpatialmatches = cacheSpatialmatches || [];

            if (cacheSpatialmatches.length === 0) {
                waste.push(Object.keys(byIdx));
            }

            const spatialmatches = [];
            for (let i = 0; i < cacheSpatialmatches.length; i++) {
                spatialmatches.push(new Spatialmatch(cacheSpatialmatches[i], byIdx));
            }

            diff = hrtime_format(process.hrtime(spatialmatchStart));
            prof_file.write(`${constant_values},coalesceStack,${diff}\n`);
            callback(null, spatialmatches);
        });
    }

    // Final feature collection and sort.
    function coalesceFinalize(err, results) {
        if (err) return callback(err);
        let combined = [];
        combined = combined.concat.apply(combined, results);
        combined.sort(sortByRelev);

        // Ascending and Descending order here refers to being able to support `address, place, region, country` and `country, region, place, address`
        // Also supports being able to return a single feature that hasn't been stacked with another index
        const sets = {};
        const doneAscending = {};
        const doneDescending = {};
        const doneSingle = {};
        const filteredSpatialmatches = [];
        for (let i = 0; i < combined.length; i++) {
            const spatialmatch = combined[i];
            const covers = spatialmatch.covers;
            for (let j = 0; j < covers.length; j++) {
                if (!sets[covers[j].tmpid] || sets[covers[j].tmpid].relev < covers[j].relev) sets[covers[j].tmpid] = covers[j];
            }
            // only allow one result in each direction
            if (covers.length > 1 && covers[0].idx > covers[1].idx && !doneDescending[covers[0].tmpid]) {
                doneDescending[covers[0].tmpid] = true;
                filteredSpatialmatches.push(spatialmatch);
            } else if (covers.length > 1 && covers[0].idx < covers[1].idx && !doneAscending[covers[0].tmpid]) {
                doneAscending[covers[0].tmpid] = true;
                filteredSpatialmatches.push(spatialmatch);
            } else if (covers.length === 1 && !doneAscending[covers[0].tmpid] && !doneDescending[covers[0].tmpid] && !doneSingle[covers[0].tmpid]) {
                doneSingle[covers[0].tmpid] = true;
                filteredSpatialmatches.push(spatialmatch);
            }
        }


        diff = hrtime_format(process.hrtime(spatialmatchStart));
        prof_file.write(`${constant_values},coalesceFinalize,${diff}\n`);
        prof_file.write(`---\n`);
        prof_file.end()
        return callback(null, { results: filteredSpatialmatches, sets: sets, waste: waste });
    }
}

function collapseToArchetypes(phrasematchResults) {
    const outResults = [];
    for (const inResult of phrasematchResults) {
        const uniqMap = new Map();
        for (const inMatch of inResult.phrasematches) {
            const signature = inMatch.mask + '-' + inMatch.weight + '-' + inMatch.editMultiplier;
            let outMatch = uniqMap.get(signature);
            if (!outMatch) {
                outMatch = {
                    mask: inMatch.mask,
                    weight: inMatch.weight,
                    editMultiplier: inMatch.editMultiplier,
                    zoom: inMatch.zoom,
                    idx: inResult.idx,
                    exemplars: []
                };
                uniqMap.set(signature, outMatch);
            }
            outMatch.exemplars.push(inMatch);
        }
        outResults.push({
            phrasematches: Array.from(uniqMap.values()),
            idx: inResult.idx,
            nmask: inResult.nmask,
            bmask: inResult.bmask
        });
    }
    diff = hrtime_format(process.hrtime(spatialmatchStart));
    prof_file.write(`${constant_values},collapseToArchetypes,${diff}\n`);
    return outResults;
}

function expandFromArchetypes(stacks, maxOut) {
    const out = [];
    for (const stack of stacks) {
        const done = expandFromArchetypesInner(stack, maxOut, 0, [], out);
        if (done) break;
    }
    return out;
}

function expandFromArchetypesInner(stack, maxOut, matchIdx, soFar, out) {
    if (matchIdx === stack.length - 1) {
        // this is innermost recursion round
        for (const exemplar of stack[matchIdx].exemplars) {
            const outStack = soFar.slice();
            outStack.push(exemplar);
            outStack.relev = stack.relev;
            outStack.adjRelev = stack.adjRelev;
            out.push(outStack);
            if (out.length >= maxOut) return true;
        }
        diff = hrtime_format(process.hrtime(spatialmatchStart));
        prof_file.write(`${constant_values},expandFromArchetypesInner,${diff}\n`);
        return false;
    } else {
        for (const exemplar of stack[matchIdx].exemplars) {
            const outStack = soFar.slice();
            outStack.push(exemplar);
            const done = expandFromArchetypesInner(stack, maxOut, matchIdx + 1, outStack, out);
            if (done) return done;
        }
        diff = hrtime_format(process.hrtime(spatialmatchStart));
        prof_file.write(`${constant_values},expandFromArchetypesInner,${diff}\n`);
        return false;
    }
}

// Filter an array of stacks down to only those whose maxidx is allowed
// by a passed in allowed_idx filter.
function allowed(stacks, options) {
    if (!options.allowed_idx) return stacks;
    const filtered = [];
    for (let i = 0; i < stacks.length; i++) {
        let stack_maxidx = 0;
        for (let j = 0; j < stacks[i].length; j++) {
            stack_maxidx = Math.max(stack_maxidx, stacks[i][j].idx);
        }
        if (options.allowed_idx[stack_maxidx]) {
            filtered.push(stacks[i]);
        }
    }
    diff = hrtime_format(process.hrtime(spatialmatchStart));
    prof_file.write(`${constant_values},allowed,${diff}\n`);
    return filtered;
}

function stackByIdx(stack) {
    const byIdx = {};
    let l = stack.length;
    while (l--) byIdx[stack[l].idx] = stack[l];
    return byIdx;
}

// For a given set of phrasematch results across multiple indexes,
// provide all relevant stacking combinations using phrase masks to
// exclude colliding matches.
// Features can't be stacked together if:
// 1. The bmask of an index represents a mask of all indexes that their geocoder_stacks do not intersect with, so if an index's bmask contains
// the idx of the next index they cannot be stacked together
// 2. The nmask of an index is the bitmasks of all the tokens in the subquery. Two indexes that have the same nmask should not be stacked together. For example: `main st` in new york and `st martin` in new york shouldn't be stacked together
// 3. If two features have the same mask values they shouldn't be stacked together

/**
*
* stackable
* @params {Array} phrasematchResults generated for each subquery permutation
* @params {Object} memo memoization object, used for caching result to check relevance, masks across different indexes
* @params {Number} idx index number
* @params {Number} mask caluculated by phrasematch; is used to represent all possible cominations
* @params {Number} nmask used to determine whether to two indexes have the same tokens which means they cannot be stacked together
* @params {Array} stack a list of indexes that stack spatially
* @params {Number} relevance score for each feature
**/
function stackable(phrasematchResults, limit, memo, idx, mask, nmask, stack, relev, adjRelev) {
    if (memo === undefined) {
        memo = {
            stacks: [],
            maxStacks: [],
            maxRelev: 0
        };
        idx = 0;
        mask = 0;
        nmask = 0;
        stack = [];
        relev = 0;
        adjRelev = 0;
    }

    // Recurse, skipping this level
    if (phrasematchResults[idx + 1] !== undefined) {
        stackable(phrasematchResults, limit, memo, idx + 1, mask, nmask, stack, relev, adjRelev);
    }

    const phrasematchResult = phrasematchResults[idx];

    // For each stacked item check the next bmask for its idx.
    // If the bmask includes the idx these indexes cannot stack
    // (their geocoder_stack do not intersect at all).
    const bmask = phrasematchResult.bmask;
    for (let j = 0; j < stack.length; j++) {
        if (bmask[stack[j].idx]) return;
    }

    // Recurse, including this level
    const phrasematches = phrasematchResult.phrasematches;
    for (let i = 0; i < phrasematches.length; i++) {
        const next = phrasematches[i];
        if (mask & next.mask) continue;
        if (nmask & phrasematchResult.nmask) continue;

        // compare index order to input order to determine direction
        if (stack.length &&
            stack[0].idx >= next.idx &&
            mask &&
            mask < next.mask) continue;

        const targetStack = stack.slice(0);
        const targetMask = mask | next.mask;
        const targetNmask = nmask | phrasematchResult.nmask;
        targetStack.relev = relev + next.weight;
        targetStack.adjRelev = adjRelev + (next.weight * next.editMultiplier);

        // ensure order of targetStack maintains lowest mask value at the
        // first position. ensure direction check above works.
        if (next.mask < mask) {
            targetStack.unshift(next);
        } else {
            targetStack.push(next);
        }

        if (targetStack.relev > 0.5) {
            if (targetStack.relev > memo.maxRelev) {
                if (memo.maxStacks.length >= limit) {
                    memo.stacks = memo.maxStacks;
                    memo.maxStacks = [targetStack];
                } else {
                    memo.maxStacks.push(targetStack);
                }
                memo.maxRelev = targetStack.relev;
            } else if (targetStack.relev === memo.maxRelev) {
                memo.maxStacks.push(targetStack);
            } else if (memo.maxStacks.length < limit) {
                memo.stacks.push(targetStack);
            }
        }

        // Recurse to next level
        if (phrasematchResults[idx + 1] !== undefined) {
            stackable(phrasematchResults, limit, memo, idx + 1, targetMask, targetNmask, targetStack, targetStack.relev, targetStack.adjRelev);
        }
    }

    if (idx === 0) {
        const stacks = memo.stacks.concat(memo.maxStacks);
        for (const stack of stacks) {
            // this will hyperbolically scale from 1 asymptotically down to .9
            const lengthPenalty = .9 + (.1 / (stack.length || 1));
            stack.adjRelev *= lengthPenalty;
        }

        diff = hrtime_format(process.hrtime(spatialmatchStart));
        prof_file.write(`${constant_values},stackable,${diff}\n`);
        return stacks;
    }
}

/**
* sortByRelevLengthIdx Sorts the stacks according to the scorefactor, relevance or length
**/
function sortByRelevLengthIdx(a, b) {
    const first = (b.adjRelev - a.adjRelev) ||
        (a.length - b.length) ||
        (b.relev - a.relev) ||
        (b[b.length - 1].scorefactor - a[a.length - 1].scorefactor);
    if (first) return first;

    for (let end = a.length - 1; end >= 0; end--) {
        const second = a[end].idx - b[end].idx;
        if (second) return second;
    }
}

/**
* sortByZoomIdx Sorts stacks by zoom level
**/
function sortByZoomIdx(a, b) {
    return (a.zoom - b.zoom) || (a.idx - b.idx) || (b.mask - a.mask);
}

/**
* sortByRelev Sorts stack by relevance
**/
function sortByRelev(a, b) {
    return (b.relev - a.relev) ||
        (b.covers[0].scoredist - a.covers[0].scoredist) ||
        (a.covers[0].idx - b.covers[0].idx);
}


// Rebalancing is done to prevent cases where the number of tokens causes the relevance to cause an index to win
// over an index that actually has the feature
// For example: Martin Luther King Jr. Street, Thanjavur, Tamil Nadu would return an American city
// since Martin Luther King Jr. Street is a really long street name
// any result that contains the street(like Martin Luther King Jr. Street, Washington, DC would automatically have a higher relevance.
/**
* rebalance recalculates the relevance based on the number of tokens and number of layers that match in the result and query
* @param {Array} query a list of terms composing the query to Carmen
* @param {Array} stack results for a subquery combination
**/
function rebalance(query, stack) {
    let stackMask = 0;
    const stackClone = [];

    for (let i = 0; i < stack.length; i++) {
        stackMask |= stack[i].mask;
    }

    const garbage = (query.length === (stackMask.toString(2).split(1).length - 1)) ? 0 : 1;
    const weightPerMatch = 1 / (garbage + stack.length);

    // shallow copy stack into stackClone to prevent cases where a stack's
    // index gets overwritten in deep copies.
    let totalWeight = 0;
    for (let k = 0; k < stack.length; k++) {
        stackClone[k] = stack[k].clone();
        stackClone[k].weight = weightPerMatch * stack[k].editMultiplier;
        totalWeight += stackClone[k].weight;
    }

    stackClone.relev = totalWeight;

    diff = hrtime_format(process.hrtime(spatialmatchStart));
    prof_file.write(`${constant_values},rebalance,${diff}\n`);
    return stackClone;
}

/**
Spatialmatch recursive function to fetch the features for stacks that could be spatially stacked together
**/

function Spatialmatch(cacheSpatialmatch, stackByIdx) {
    this.relev = cacheSpatialmatch.relev;
    this.covers = [];
    for (let i = 0; i < cacheSpatialmatch.length; i++) {
        const cacheCover = cacheSpatialmatch[i];
        this.covers.push(new Cover(cacheCover, stackByIdx[cacheCover.idx]));
    }
}

function Cover(cacheCover, phrasematch) {
    this.x = cacheCover.x;
    this.y = cacheCover.y;
    this.relev = cacheCover.relev;
    this.id = cacheCover.id;
    this.idx = cacheCover.idx;
    this.tmpid = cacheCover.tmpid;
    this.distance = cacheCover.distance;
    this.score = termops.decode3BitLogScale(cacheCover.score, phrasematch.scorefactor);
    this.scoredist = cacheCover.scoredist > 7 ? (phrasematch.scorefactor / 7) * cacheCover.scoredist : termops.decode3BitLogScale(cacheCover.scoredist, phrasematch.scorefactor);
    this.scorefactor = phrasematch.scorefactor;
    this.matches_language = cacheCover.matches_language;
    this.prefix = phrasematch.prefix;

    this.mask = phrasematch.mask;
    this.text = phrasematch.subquery.join(' ');
    this.zoom = phrasematch.zoom;
}
